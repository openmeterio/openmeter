input:
  generate:
    count: ${SEEDER_COUNT:0}
    interval: "${SEEDER_INTERVAL:50ms}"
    # batch_size: 1
    mapping: |
      let max_subjects = ${SEEDER_MAX_SUBJECTS:20}
      let event_type = "tokens"
      let source = "api-gateway"
      let models = ["gpt-5", "gpt-5-mini", "gpt-5-nano"]
      let types = ["input", "output", "cache_read"]
      let subject = "customer-%d".format(random_int(seed: timestamp_unix_nano()) % $max_subjects)
      let time = now().ts_format()
      let provider = "openai"
      let model = $models.index(random_int(seed: timestamp_unix_nano()) % $models.length())
      let type = $types.index(random_int(seed: timestamp_unix_nano()) % $types.length())
      let tokens = random_int(seed: timestamp_unix_nano(), max: 100000)
      root = {
        "id": uuid_v4(),
        "specversion": "1.0",
        "type": $event_type,
        "source": $source,
        "subject": $subject,
        "time": $time,
        "data": {
          "provider": $provider,
          "model": $model,
          "type": $type,
          "tokens": $tokens,
        },
      }
output:
  switch:
    cases:
      - check: ""
        continue: true
        output:
          http_client:
            url: ${OPENMETER_BASE_URL:http://127.0.0.1:8888}/api/v1/events
            verb: POST
            headers:
              Content-Type: application/cloudevents+json
              Authorization: "Bearer ${OPENMETER_TOKEN:}"
            max_in_flight: 1

      - check: '"${SEEDER_LOG:false}" == "true"'
        output:
          stdout:
            codec: lines
